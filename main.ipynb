{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["35tyTJes_u8Z"],"toc_visible":true,"mount_file_id":"128AXMVH5RjXh-tKmeMwEPXEW1EQ70not","authorship_tag":"ABX9TyPnpB6OLZCy+rfbQ0s7M65z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# imports"],"metadata":{"id":"gsvGgpMV-TlI"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","from sklearn.impute import KNNImputer\n","import math\n","import numpy as np\n","from graphviz import Digraph\n","import random"],"metadata":{"id":"SYcULW_19wNq","executionInfo":{"status":"ok","timestamp":1714839801858,"user_tz":-210,"elapsed":424,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":421,"outputs":[]},{"cell_type":"markdown","source":["## Project_path"],"metadata":{"id":"XzRP2SyT-MhH"}},{"cell_type":"code","execution_count":422,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u7DjZT887dKT","executionInfo":{"status":"ok","timestamp":1714839801858,"user_tz":-210,"elapsed":2,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"51c33a66-76a7-41fc-f353-387b44c46191"},"outputs":[{"output_type":"stream","name":"stdout","text":["Project directory: /content/drive/My Drive/Colab Notebooks/CarClassification\n"]}],"source":["project_path = '/content/drive/My Drive/Colab Notebooks/CarClassification'\n","print(\"Project directory:\", project_path)"]},{"cell_type":"markdown","source":["# Load Datasets"],"metadata":{"id":"35tyTJes_u8Z"}},{"cell_type":"code","source":["dataset = pd.read_csv(f'{project_path}/datasets/original.train_ds.csv')\n","test = pd.read_csv(f'{project_path}/datasets/original.test_ds.csv')\n","# target_label = 'transmission'\n","# target_label = 'Manufacturer'\n","target_label = 'model'"],"metadata":{"id":"nKTbW35v-eHx","executionInfo":{"status":"ok","timestamp":1714839861253,"user_tz":-210,"elapsed":287,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":423,"outputs":[]},{"cell_type":"markdown","source":["# Pre Process"],"metadata":{"id":"JzlQg7lhsaSp"}},{"cell_type":"markdown","source":["## Drop Nulls"],"metadata":{"id":"V-MK5Azww77m"}},{"cell_type":"code","source":["cleaned_dataset = dataset.dropna()"],"metadata":{"id":"PhF55iTCwbOZ","executionInfo":{"status":"ok","timestamp":1714839864008,"user_tz":-210,"elapsed":361,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":424,"outputs":[]},{"cell_type":"markdown","source":["## FFILL"],"metadata":{"id":"p-PyRkRHwUWM"}},{"cell_type":"code","source":["cleaned_dataset = dataset.fillna(method='ffill')"],"metadata":{"id":"2b20Jiq2sCBz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## BFILL"],"metadata":{"id":"joVHqwdbr6-9"}},{"cell_type":"code","source":["cleaned_dataset = dataset.fillna(method='bfill')"],"metadata":{"id":"CPz_X5-sw1zm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fill Numeric Values"],"metadata":{"id":"97wsTgENwEME"}},{"cell_type":"markdown","source":["### Mean"],"metadata":{"id":"Jr2nEWW8m3tH"}},{"cell_type":"code","source":["numeric_dataset = dataset.select_dtypes(include=['number'])\n","numeric_dataset.fillna(numeric_dataset.mean(), inplace=True)"],"metadata":{"id":"feoy2mf6n2sO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Median"],"metadata":{"id":"53uExhIdm8P8"}},{"cell_type":"code","source":["numeric_dataset = dataset.select_dtypes(include=['number'])\n","numeric_dataset.fillna(numeric_dataset.median(), inplace=True)"],"metadata":{"id":"eUap2CFeoLrl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Mode"],"metadata":{"id":"RGS7T5Sjm_6Q"}},{"cell_type":"code","source":["numeric_dataset = dataset.select_dtypes(include=['number'])\n","numeric_dataset.fillna(numeric_dataset.mode()[0], inplace=True)"],"metadata":{"id":"LSVIgsUToRXa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Custom Value"],"metadata":{"id":"Fa1NWEYrnJUP"}},{"cell_type":"code","source":["numeric_dataset = dataset.select_dtypes(include=['number'])\n","numeric_dataset.fillna(value=1, inplace=True)"],"metadata":{"id":"pKIC3gNxoW5_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Interpolate Linear"],"metadata":{"id":"NwxTamDjnNXM"}},{"cell_type":"code","source":["numeric_dataset = dataset.select_dtypes(include=['number'])\n","numeric_dataset.interpolate(method='linear', inplace=True)"],"metadata":{"id":"LiwbLldSog0n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fill Categorical"],"metadata":{"id":"Wd0DbNb6wOPk"}},{"cell_type":"code","source":["categorical_dataset = dataset.select_dtypes(include=['object'])\n","for col in categorical_dataset.columns:\n","    mode_value = categorical_dataset[col].mode()[0]\n","    categorical_dataset[col].fillna(mode_value, inplace=True)"],"metadata":{"id":"n-SuHuzswk_X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Concat Numeric & Categircal"],"metadata":{"id":"V5H8byYPrctV"}},{"cell_type":"code","source":["cleaned_dataset =  pd.concat([categorical_dataset, numeric_dataset], axis=1)"],"metadata":{"id":"KYZAU99RrbWk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Helper functions"],"metadata":{"id":"cEWXSfmWYK2a"}},{"cell_type":"code","source":["def is_discrete(labels:pd.DataFrame.columns):\n","  if(labels.dtype == 'int64'):\n","    num_unique = labels.nunique()\n","    if(num_unique < 20):\n","      return True\n","  return False\n","\n","def float_detector(dataset):\n","  for col in dataset.select_dtypes(include='float'):\n","    if (dataset[col] % 1 == 0).all():  # Check if all values are integers\n","      dataset[col] = dataset[col].astype(int)\n","  return dataset\n","\n","def random_outcome(labels):\n","  model_counts = labels.value_counts()\n","  total_count = model_counts.sum()\n","  probabilities = model_counts / total_count\n","  outcomes = list(zip(probabilities.index, probabilities))\n","  random_number = random.random()\n","\n","  cumulative_probability = 0\n","  for outcome, probability in outcomes:\n","    cumulative_probability += probability\n","    if random_number < cumulative_probability:\n","        return outcome\n","        break\n","\n","def probilities_outcome(labels):\n","  model_counts = labels.value_counts()\n","  total_count = model_counts.sum()\n","  probabilities = model_counts / total_count\n","  outcomes = list(zip(probabilities.index, probabilities))\n","  temp_dict = {}\n","\n","  for outcome, probability in outcomes:\n","    temp_dict[outcome] = probability\n","  return temp_dict\n","\n","\n","def find_optimal_threshold(data, numeric_column):\n","  unique_values = sorted(data[numeric_column].unique())\n","  optimal_threshold = None\n","  max_info_gain = float('-inf')\n","  for i in range(len(unique_values) - 1):\n","      threshold = (unique_values[i] + unique_values[i+1]) / 2  # Calculate threshold as midpoint\n","      left_split = data[data[numeric_column] <= threshold]\n","      right_split = data[data[numeric_column] > threshold]\n","\n","      info_gain = cal_information_gain(left_split[numeric_column], right_split[numeric_column])\n","\n","      if info_gain > max_info_gain:\n","          optimal_threshold = threshold\n","          max_info_gain = info_gain\n","\n","  if optimal_threshold is None or np.isnan(optimal_threshold):\n","    return np.float64(data[numeric_column].mean())\n","  return optimal_threshold\n","\n","def cal_information_gain(left_labels, right_labels):\n","\n","    parent_entropy = entropy(np.concatenate((left_labels, right_labels)))\n","    total_samples = len(left_labels) + len(right_labels)\n","    weighted_entropy = (len(left_labels) / total_samples) * entropy(left_labels) \\\n","                        + (len(right_labels) / total_samples) * entropy(right_labels)\n","\n","    information_gain = parent_entropy - weighted_entropy\n","    return information_gain\n","def entropy(labels):\n","    unique_labels, counts = np.unique(labels, return_counts=True)\n","    probabilities = counts / len(labels)\n","    entropy = -np.sum(probabilities * np.log2(probabilities))\n","    return entropy\n","\n","def calculate_information_gain(feature, parent_label, child_labels):\n","\n","  child_labels = [label.root.data[feature] for label in child_labels]\n","  parent_entropy = entropy(parent_label[feature])\n","  total_samples = len(parent_label[feature])\n","  if total_samples == 0:\n","      return 0  # Avoid division by zero\n","  weighted_entropy = 0\n","  for labels in child_labels:\n","    branch_samples = len(labels)\n","    weighted_entropy += (branch_samples / total_samples) * entropy(labels)\n","  information_gain = parent_entropy - weighted_entropy\n","  return information_gain"],"metadata":{"id":"SI4gzhqjru2L","executionInfo":{"status":"ok","timestamp":1714839867518,"user_tz":-210,"elapsed":308,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":425,"outputs":[]},{"cell_type":"markdown","source":["# Float to Integer Convertion"],"metadata":{"id":"lXc720rRth6l"}},{"cell_type":"code","source":["cleaned_dataset = float_detector(cleaned_dataset)\n","print(cleaned_dataset.dtypes)\n","cleaned_test = test"],"metadata":{"id":"66i7uk4o3f0q","executionInfo":{"status":"ok","timestamp":1714839870764,"user_tz":-210,"elapsed":347,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6fd803b0-7783-4013-f361-86b5b5f65b5d"},"execution_count":426,"outputs":[{"output_type":"stream","name":"stdout","text":["model            object\n","year              int64\n","price             int64\n","transmission     object\n","mileage           int64\n","fuelType         object\n","tax               int64\n","mpg             float64\n","engineSize      float64\n","Manufacturer     object\n","dtype: object\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-425-6d6fe088bb5a>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  dataset[col] = dataset[col].astype(int)\n","<ipython-input-425-6d6fe088bb5a>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  dataset[col] = dataset[col].astype(int)\n","<ipython-input-425-6d6fe088bb5a>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  dataset[col] = dataset[col].astype(int)\n","<ipython-input-425-6d6fe088bb5a>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  dataset[col] = dataset[col].astype(int)\n"]}]},{"cell_type":"markdown","source":["# Discretization"],"metadata":{"id":"n2nbWKA5t3hd"}},{"cell_type":"markdown","source":["## No Discretization"],"metadata":{"id":"uQ567pMVvqxK"}},{"cell_type":"code","source":["discrete_features = {feature: False for feature in cleaned_dataset.columns}\n","print(discrete_features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7yGtaUKUvqLf","executionInfo":{"status":"ok","timestamp":1714839872382,"user_tz":-210,"elapsed":372,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"7a9ef066-53be-46e3-8d07-a7b5d69c019e"},"execution_count":427,"outputs":[{"output_type":"stream","name":"stdout","text":["{'model': False, 'year': False, 'price': False, 'transmission': False, 'mileage': False, 'fuelType': False, 'tax': False, 'mpg': False, 'engineSize': False, 'Manufacturer': False}\n"]}]},{"cell_type":"markdown","source":["## Yes Discretization"],"metadata":{"id":"eAvkYYZlvwMR"}},{"cell_type":"code","source":["discrete_features = {feature: is_discrete(cleaned_dataset[feature]) for feature in cleaned_dataset.columns}\n","print(discrete_features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cki68VuprfR5","executionInfo":{"status":"ok","timestamp":1714762628349,"user_tz":-210,"elapsed":3,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"b4a2fa3e-ff89-45bd-c19c-c6c128578a36"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'model': False, 'year': True, 'price': False, 'transmission': False, 'mileage': False, 'fuelType': False, 'tax': True, 'mpg': False, 'engineSize': False, 'Manufacturer': False}\n"]}]},{"cell_type":"markdown","source":["#Node"],"metadata":{"id":"nYdmcYXTX-dG"}},{"cell_type":"code","source":["class Node:\n","  def __init__(self, data:pd.DataFrame, features: pd.DataFrame.columns, label, discerete_features={}, value = None) -> None:\n","     self.data = data\n","     self.features = features\n","     self.label = label\n","     self.value = value\n","     self.discerete_features = discerete_features\n",""],"metadata":{"id":"SR5h1hO9971-","executionInfo":{"status":"ok","timestamp":1714839873946,"user_tz":-210,"elapsed":316,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":428,"outputs":[]},{"cell_type":"markdown","source":["# Decision Tree"],"metadata":{"id":"bai1dA7X3USz"}},{"cell_type":"code","source":["class Tree:\n","  def __init__(self, root:Node, depth=0, split_method='entropy', target_label='model') -> None:\n","     self.root = root\n","     self.depth = depth\n","     self.split_method = split_method\n","     self.target_label = target_label\n","     self.branches = {}\n","     self.features_ig = {key: 0 for key in self.root.features}\n","\n","  def build(self) -> 'Tree':\n","\n","    if len(self.root.features) == 1 and len(self.root.data) > 1:\n","      # self.root.value = probilities_outcome(self.root.data[self.target_label])\n","      self.root.value = random_outcome(self.root.data[self.target_label])\n","      self.root.label = self.root.value\n","    elif len(self.root.data) == 1:\n","      # self.root.value = probilities_outcome(self.root.data[self.target_label])\n","      # self.root.value = random_outcome(self.root.data[self.target_label])\n","      self.root.value = self.root.data[self.target_label].value_counts().idxmax()\n","      self.root.label = self.root.value\n","    elif self.root.data.empty:\n","      self.root.label = None\n","      self.root.value = None\n","    else:\n","      selected_feature = self.feature_selector(self.split_method, self.root.features)\n","      self.branches = self.split(self.root.data, selected_feature)\n","      for branch in self.branches:\n","        self.branches[branch].build()\n","\n","  def feature_selector(self, mode, features):\n","    if(mode == 'entropy'):\n","      features_entropy = {key: 0 for key in self.root.features}\n","      for feature in features:\n","        if(feature == self.target_label):\n","        # if(feature == 'model'):\n","          feature_entropy = float('+inf')\n","        else:\n","          feature_entropy = entropy(self.root.data[feature].to_list())\n","        features_entropy[feature] = feature_entropy\n","\n","      selected_feature = min(features_entropy, key=features_entropy.get)\n","    elif(mode == 'information_gain'):\n","      features_ig = {key: 0 for key in self.root.features}\n","      for feature in features:\n","        if(feature == self.target_label):\n","        # if(feature == 'model'):\n","          feature_ig = float('-inf')\n","        else:\n","          branches = self.split(self.root.data, feature)\n","          parent_branch = self.root.data\n","\n","          feature_ig = calculate_information_gain(self.target_label, parent_branch, list(branches.values()))\n","          # feature_ig = calculate_information_gain('model', parent_branch, list(branches.values()))\n","        features_ig[feature] = feature_ig\n","\n","      selected_feature = max(features_ig, key=features_ig.get)\n","\n","    return selected_feature\n","\n","  def split(self, data, feature) -> tuple:\n","    branches = {}\n","    if(data[feature].dtype == 'object'):\n","      branches = self.split_categorical(data, feature)\n","    elif(self.root.discerete_features[feature]):\n","      branches = self.split_categorical(data, feature)\n","    else:\n","      branches = self.split_numeric(data, feature)\n","    return branches\n","\n","\n","  def split_numeric(self, data, feature):\n","    threshold = find_optimal_threshold(self.root.data, feature)\n","\n","    # threshold = data[feature].mean()\n","    branches = {}\n","    left_data = data[data[feature] <= threshold].drop(feature, axis=1)\n","    left_node = Node(left_data, left_data.columns, label=f'{feature}*{threshold}*left', discerete_features=self.root.discerete_features)\n","    left_tree = Tree(left_node, depth=self.depth+1, split_method=self.split_method, target_label = self.target_label)\n","    branches[f'{feature}*{threshold}*left'] = left_tree\n","\n","    right_data = data[data[feature] > threshold].drop(feature, axis=1)\n","    right_node = Node(right_data, right_data.columns, label=f'{feature}*{threshold}*right', discerete_features=self.root.discerete_features)\n","    right_tree = Tree(right_node, depth=self.depth+1, split_method=self.split_method, target_label = self.target_label)\n","    branches[f'{feature}*{threshold}*right'] = right_tree\n","    return branches\n","\n","  def split_categorical(self, data, feature):\n","    branches = {}\n","    for data_point in set(data[feature]):\n","      new_data = data[data[feature] == data_point].drop(feature, axis=1)\n","      new_root = Node(new_data, new_data.columns, label=f'{feature}*{data_point}', discerete_features=self.root.discerete_features)\n","      branches[f'{feature}*{data_point}'] = Tree(new_root, depth=self.depth+1, split_method=self.split_method, target_label = self.target_label)\n","    return branches\n","\n","\n","\n","\n","  def visualize(self, path):\n","    dot = Digraph()\n","    self._visualize_helper(dot, self)\n","    dot.render(path, format='png', cleanup=True)\n","\n","  def _visualize_helper(self, dot, parent):\n","\n","    if parent.root.label is None:\n","      return\n","    dot.node(str(id(parent)), label=self.root.label)\n","    if self.root.value:\n","      return\n","    for branch in self.branches:\n","      if self.branches[branch].root.label is None:\n","        return\n","      edge_label = '*'.join(self.branches[branch].root.label.split('*')[1:])\n","      self.branches[branch]._visualize_helper(dot, self.branches[branch])\n","      dot.edge(str(id(parent)), str(id(self.branches[branch])), label=edge_label)\n","\n","  # def _visualize_helper(self, dot, parent_label):\n","  #   edge_label = '*'.join(parent_label.split('*')[1:])\n","  #   print('parent',parent_label.split('*')[0])\n","  #   print(self.root.label , '**',self.root.value)\n","  #   dot.node(str(id(parent_label)), label=str(self.root.label))\n","  #   if self.root.value:\n","  #     return\n","  #   for branch in self.branches:\n","  #     self.branches[branch]._visualize_helper(dot, branch)\n","  #     dot.edge(str(id(parent_label)), branch, label=edge_label)\n","\n","\n","  def predict(self, data_point: pd.DataFrame):\n","    if self.root.value is not None:\n","      return self.root.value\n","    else:\n","      for branch in self.branches:\n","        if branch.endswith('left'):\n","          branch_parts = branch.split('*')\n","          feature = branch_parts[0]\n","          threshold = float(branch_parts[1])\n","          if(data_point.iloc[0][feature] <= threshold):\n","            # print(data_point)\n","            # print(branch)\n","            new_data_point = data_point.drop(feature, axis=1)\n","            return self.branches[branch].predict(new_data_point)\n","\n","        elif branch.endswith('right'):\n","          branch_parts = branch.split('*')\n","          feature = branch_parts[0]\n","          threshold = float(branch_parts[1])\n","          if(data_point.iloc[0][feature] > threshold):\n","            # print(data_point)\n","            # print(branch)\n","            new_data_point = data_point.drop(feature, axis=1)\n","            return self.branches[branch].predict(new_data_point)\n","        else:\n","          branch_parts = branch.split('*')\n","          feature = branch_parts[0]\n","          feature_value = branch_parts[1]\n","          if str(data_point.iloc[0][feature]) == str(feature_value):\n","            # print(data_point)\n","            # print(branch)\n","            new_data_point = data_point.drop(feature, axis=1)\n","            return self.branches[branch].predict(new_data_point)\n"],"metadata":{"id":"rNM0kxAf51Vy","executionInfo":{"status":"ok","timestamp":1714840150203,"user_tz":-210,"elapsed":298,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":435,"outputs":[]},{"cell_type":"markdown","source":["# Build Tree"],"metadata":{"id":"yZPntOUVv9kD"}},{"cell_type":"markdown","source":["## Entropy"],"metadata":{"id":"LQvisspqxpmm"}},{"cell_type":"code","source":["node = Node(cleaned_dataset ,cleaned_dataset.columns, 'root', discrete_features)\n","tree = Tree(node, split_method='entropy', target_label=target_label)\n","# tree.calculate_ig()\n","tree.build()"],"metadata":{"id":"MtoLATsWxyiv","executionInfo":{"status":"ok","timestamp":1714840158809,"user_tz":-210,"elapsed":5393,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":436,"outputs":[]},{"cell_type":"markdown","source":["## Information Gain"],"metadata":{"id":"D4fX139txt2C"}},{"cell_type":"code","source":["\n","node = Node(cleaned_dataset ,cleaned_dataset.columns, 'root', discrete_features)\n","tree = Tree(node, split_method='information_gain', target_label=target_label)\n","# tree.calculate_ig()\n","tree.build()"],"metadata":{"id":"UI5sDFSf-ugq","executionInfo":{"status":"ok","timestamp":1714840255966,"user_tz":-210,"elapsed":29994,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":438,"outputs":[]},{"cell_type":"code","source":["test_pd = cleaned_test.iloc[[1]].copy()\n","# test_pd = cleaned_dataset.iloc[[2]].copy()\n","print(test_pd)\n","result = tree.predict(test_pd)\n","print(result, test_pd.iloc[0][target_label])"],"metadata":{"id":"r8pcIDFJIByp","executionInfo":{"status":"ok","timestamp":1714839529706,"user_tz":-210,"elapsed":299,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c1d38587-b8e1-4ea0-d90b-b1d3b67b71d8"},"execution_count":413,"outputs":[{"output_type":"stream","name":"stdout","text":["       model  year  price transmission  mileage fuelType  tax   mpg  \\\n","1   2 Series  2019  24590    Semi-Auto     3300   Diesel  145  48.7   \n","\n","   engineSize Manufacturer  \n","1         2.0          BMW  \n"," 1 Series  2 Series\n"]}]},{"cell_type":"markdown","source":["# Accuracy"],"metadata":{"id":"ZiUIzoQIwCUL"}},{"cell_type":"markdown","source":["## Train Accuracy"],"metadata":{"id":"AQsz2u18wJds"}},{"cell_type":"code","source":["count = 0\n","for i in range(len(cleaned_dataset)):\n","  test_pd = cleaned_dataset.iloc[[i]].copy()\n","  result = tree.predict(test_pd)\n","  # for outcome in result:\n","  #   if outcome == test_pd.iloc[0][target_label]:\n","  #     count+=1\n","  if result == test_pd.iloc[0][target_label]:\n","    count+=1\n","print(count/ len(cleaned_dataset))"],"metadata":{"id":"XPrz5zn0sGYp","executionInfo":{"status":"ok","timestamp":1714833231070,"user_tz":-210,"elapsed":8241,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4a58caff-4b9a-4b88-bc52-2951629a6026"},"execution_count":296,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9311064718162839\n"]}]},{"cell_type":"markdown","source":["## Test Accuracy"],"metadata":{"id":"2peU9XWJwNly"}},{"cell_type":"code","source":["count = 0\n","for i in range(len(cleaned_test)):\n","  test_pd = cleaned_test.iloc[[i]].copy()\n","  result = tree.predict(test_pd)\n","  if result is None:\n","    continue\n","  # for outcome in result:\n","  #   if outcome == test_pd.iloc[0][target_label]:\n","  #     count+=1\n","  if result == test_pd.iloc[0][target_label]:\n","    count+=1\n","print(count/ len(cleaned_test))"],"metadata":{"id":"2l5DvKJZIS7F","executionInfo":{"status":"ok","timestamp":1714839549782,"user_tz":-210,"elapsed":5776,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9d7fb297-d0ee-4ba4-cf06-61a0a71cd3bf"},"execution_count":414,"outputs":[{"output_type":"stream","name":"stdout","text":["0.5433333333333333\n"]}]},{"cell_type":"markdown","source":["# Visualize"],"metadata":{"id":"pMEHnBgjwewq"}},{"cell_type":"code","source":["tree.visualize(f'{project_path}/results/IG_tree')\n","# tree.visualize(f'{project_path}/results/Entropy_tree')"],"metadata":{"id":"fixtAeeO8q-m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714840259529,"user_tz":-210,"elapsed":3573,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"bb15f67a-66ff-4429-db78-8c78b2912730"},"execution_count":439,"outputs":[{"output_type":"stream","name":"stderr","text":["dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.413521 to fit\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","def entropy(labels):\n","    # Calculate the proportion of each class in the labels\n","    value_counts = labels.value_counts() / len(labels)\n","    # Filter out zero probabilities to avoid log(0) errors\n","    value_counts = value_counts[value_counts > 0]\n","    # Calculate entropy\n","    entropy = -np.sum(value_counts * np.log2(value_counts))\n","    return entropy\n","\n","def information_gain(parent_label, splits):\n","    # Calculate the entropy of the parent node\n","    parent_entropy = entropy(parent_label)\n","    total_samples = len(parent_label)\n","\n","    # Calculate the weighted entropy of the child nodes\n","    weighted_entropy = sum(len(split) / total_samples * entropy(split) for split in splits)\n","\n","    # Calculate information gain\n","    information_gain = parent_entropy - weighted_entropy\n","    return information_gain\n","\n","def calculate_information_gains(data, target_col):\n","    parent_entropy = entropy(data[target_col])\n","    information_gains = {}\n","    for feature in data.columns:\n","        if feature != target_col:\n","            splits = [data[data[feature] == value][target_col] for value in data[feature].unique()]\n","            information_gains[feature] = information_gain(data[target_col], splits)\n","    return information_gains\n","\n","# Example usage:\n","# Assuming 'data' is your pandas DataFrame and 'target_col' is the name of your target variable column\n","data = cleaned_dataset\n","all = {}\n","for col in cleaned_dataset:\n","\n","  target_col = col  # Replace 'target' with the name of your target variable column\n","  information_gains = calculate_information_gains(data, target_col)\n","  all[col] = information_gains\n","  print(f\"Information Gains for {col}:\", information_gains)\n"],"metadata":{"id":"nMzlMbwdE8D8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(all)"],"metadata":{"id":"ttH08nvMHu6E","executionInfo":{"status":"aborted","timestamp":1714834430535,"user_tz":-210,"elapsed":2,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["average_information_gains = {}\n","for feature, gains in all.items():\n","    average_gain = sum(gains.values()) / len(gains)\n","    average_information_gains[feature] = average_gain\n","\n","# Find the feature with the highest average information gain\n","highest_average_gain_feature = max(average_information_gains, key=average_information_gains.get)\n","highest_average_gain = average_information_gains[highest_average_gain_feature]\n","\n","print(\"Feature with the highest average information gain:\", highest_average_gain_feature)\n","print(\"Highest average information gain:\", highest_average_gain)"],"metadata":{"id":"tlnakfVOiU7B","executionInfo":{"status":"aborted","timestamp":1714834430535,"user_tz":-210,"elapsed":2,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ilh_p1DPH793","executionInfo":{"status":"aborted","timestamp":1714834430535,"user_tz":-210,"elapsed":2,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":null,"outputs":[]}]}